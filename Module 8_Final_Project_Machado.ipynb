{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     Time Series Analysis on the\n",
    "#        Monthly Retail Trade Servey (MRTS) Data\n",
    "\n",
    "**Chris Machado**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "<img align=\"right\" width=\"400\" src=\"ecommerce.jpg\">\n",
    "\n",
    "- [Abstract](#Abstract)\n",
    "- [1. Introduction](#1.-Introduction)\n",
    "- [2. Extract-Transform-Load](#2.-Extract-Transform-Load)\n",
    "    - [2.1 The ETL Process](#2.1-The-ETL-Process)\n",
    "    - [2.2 Data Exploration](#2.2-Data-Exploration)\n",
    "    - [2.3 Data Preparation](#2.3-Data-Preparation)\n",
    "    - [2.4 Read the Data Using Python](#2.4-Reading-the-Data-Using-Python)\n",
    "         - [2.4.1 Reading Sample Data](#2.4.1-Reading-Sample-Data)\n",
    "         - [2.4.2 Reading the MRST Data](#2.4.2-Reading-the-MRST-Data)\n",
    "    - [2.5 Writing an Installation Script](#2.5-Writing-an-Installation-Script)\n",
    "- [3. Analysis and Visualization](#3.-Analysis-and-Visualization)\n",
    "    - [3.1 Running Queries in MySQL Workbech](#3.1-Running-Queries-in-MySQL-Workbech)\n",
    "    - [3.2 Running Queries From Python](#3.2-Running-Queries-From-Python)\n",
    "    - [3.3 Explore Trends](#3.3-Explore-Trends)\n",
    "    - [3.4 Explore Percentage Change](#3.4-Explore-Percentage-Change)\n",
    "    - [3.5 Explore Rolling Time Windows](#3.5-Explore-Rolling-Time-Windows)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "\n",
    "##  Abstract\n",
    "\n",
    "The Monthly Retail Trade Survey (MRTS) dataset contains estimated spending activity across the U.S. going back 28 years and for 59 different business categories. The Extract-Transform-Load (ETL) sequence is used to upload onto a MySQL server. From there, data is queried using python, and multiple time series are analyzed\n",
    "\n",
    "The plots reveal details about business sectors and consumer spending habits. Furniture stores are susceptible to recessions while e-commerce isn't. Internet spending is growing in popularity, while books stores are on the decline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this project, I journey through the process of taking raw data from the public domain, and transforming it into relevant information. \n",
    "\n",
    "Starting with an Excel file, I work through the Extract-Transform-Load (ETL) process. I reshape and clean it using python. Then develop a loading script where the data is stored on a local MySQL server.\n",
    "\n",
    "Using MySQL Workbench as test bench for writing queries, I move them over, embedding into a python script. This targeted data is then used for analysis. I look at several time series that show increasing and decreasing trends, impacts felt from recessions, and even holiday spending patterns. I make use of percentage change, and explore rolling time windows to help make the charts more readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 2. Extract-Transform-Load\n",
    "\n",
    "\n",
    "#### The full ETL script can be found [here](Project8.1-ETL-Machado.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.1 The ETL Process\n",
    "\n",
    "Prior to analyzing the dataset, it needs reformatting and placement into a repository for future and easier access. This was accomplished through the extract, transform, and load process. The dataset is available for public download at the [census.gov](https://www.census.gov/retail/mrts/historic_releases.html) website in an Excel document, going back to 1992. \n",
    "\n",
    "The data is organized by year in separate worksheets, then further divided by month with 60 business categories. Extraction was completed by looping over each of the worksheets pulling the relevant data. It was then transformed by reshaping and cleaning the data, exporting a tidy csv file to the local directory. \n",
    "\n",
    "Finally the transformed data was loaded from an integrated development environment (IDE) to a MySQL server by use of a driver and script looping over each of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.2 Data Exploration\n",
    "\n",
    "The MRTS data is an estimate of total U.S. retail sales by category, collected each month. The surveys capture current economic activity in the retail trade and food service sectors. The data is derived from a sample drawn from the businesses register containing all U.S. retail businesses with paid employees. The sample size is approximately 13,000.\n",
    "\n",
    "Many economic indicators are derived from the MRTS. Gross Domestic Product (GDP), Consumer Price index (CPI), and Producer Price Index (PPI) are just a few. These indicators help gauge the health of the U.S. economy and guide policy decisions. \n",
    "\n",
    "Businesses also leverage the data. Through analysis, market trends and consumer habits are used to make decisions in the best interest of the organization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.3 Data Preparation\n",
    "\n",
    "<img style=\"float: right;\" src=\"excel1.png\"/>\n",
    "\n",
    "</br>\n",
    "\n",
    "* The data we are interested in is embedded in the Excel file surrounded by a few unwanted cells and columns. The title and header rows don't contain data and need to go. \n",
    "\n",
    "\n",
    "* The bottom half contains seasonally adjusted data. Because it is modified, we will exclude for analysis. \n",
    "\n",
    "\n",
    "* The first several rows and last column contain totals. Those can be calculated later if needed. \n",
    "\n",
    "\n",
    "* The North American Industry Classification System (NAICS) codes also wonâ€™t help in the analysis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.4 Read the Data Using Python\n",
    "\n",
    "Python can ingest the data in a couple different ways. The first is through the comma separated variables (csv) module. The Excel document needs to first be exported as a csv file. Python can then open and read through the csv.reader function. This method allows for quick and easy shaping functions in excel (i.e. deleting columns and rows), however, each spreadsheet needs to be altered and exported separately.\n",
    "\n",
    "Another method is through use of pandas read_excel function. When executed, the spreadsheet is loaded as a dataframe. A looping script can quickly ingest the data from each sheet.\n",
    "\n",
    "There are several other libraries out there designed to work with .xls/.xlsx files. I won't go over them, since I chose to use the pandas method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.4.1 Reading Sample Data\n",
    "\n",
    "Before trying to ingest a large dataset, it is a good idea to start small and ensure the scripts function as intended. I created a simple file, test.xls, then loaded it with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>color</th>\n",
       "      <th>shape</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>red</td>\n",
       "      <td>sphere</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orange</td>\n",
       "      <td>orange</td>\n",
       "      <td>sphere</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pear</td>\n",
       "      <td>green</td>\n",
       "      <td>oval</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bananna</td>\n",
       "      <td>yello</td>\n",
       "      <td>oblong</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watermellon</td>\n",
       "      <td>green</td>\n",
       "      <td>oval</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Item    color    shape   weight\n",
       "0        Apple      red   sphere      1.5\n",
       "1       Orange   orange   sphere      2.2\n",
       "2         Pear    green     oval      1.7\n",
       "3      Bananna    yello   oblong      2.3\n",
       "4  Watermellon    green     oval     24.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_excel('test.xls') \n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.4.2 Reading the MRTS Data\n",
    "\n",
    "#### Extract and Transform\n",
    "<img style=\"float: left;\" src=\"script-cutline.png\"/>\n",
    "\n",
    "Extracting the data is accomplished by looping over each year's spreadsheet, 1992 to 2020, and loading the desired cells into a dataframe. Each year's data is then reshaped and cleaned before being concatenated to a single dataframe *prep_data*.  \n",
    "\n",
    "Fortunately the spreadsheet layout has remained fairly consistent over the years. Business categories did not change, and all data remains in the same cell numbers, making it easier to extract. The only observed changes to the structure are in the notes section at the bottom.\n",
    "\n",
    "Prior to loading the file, it is important to identify where the footer begins. In other words, what bottom rows should be excluded. The read_csv function has both skiprows and skipfooter options that partitions the top and bottom user defined rows respectively. Noticing the footer changed in 2001 and 2017, I declared a variable *cut_line* that specifies how many rows to include in the footer, depending on the year.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-loadfile.png\"/>\n",
    "\n",
    "The dataframe *data* is defined, extracting from the desired worksheet, and omitting the header, unwanted rows, and footer.\n",
    "\n",
    "Next, I dropped the columns *TOTAL* and *NAICS Code*. Then assigned the name *dates* to the empty top left cell. \n",
    "\n",
    "</br></br>\n",
    "\n",
    "The presence of apostrophes in the business categories column will cause errors later when loaded into database queries, so they were removed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-transpose.png\"/>\n",
    "\n",
    "Logically structuring the dataframe for use in a database requires swapping the column headers and indexes. For this, the transpose function is called ensuring our rows contain sequential dates and our columns renamed to correspond with the type of business in a new dataframe *data_T*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-date.png\"/>\n",
    "\n",
    "The dates are in a non-standard format (*MMM. YYYY*). Since the intended destination is an SQL database, a conversion is needed to a format accepted by the server. This was done by first splitting string on the period \".,\" so month and year became separate items. \n",
    "\n",
    "At this point I discovered the month of may did not have a period. Under further inspection, I found this to be true for each year. It seems as though this minor detail was in the Census Boroughâ€™s original scripting, and the error carried forward since 1992. To fix, I needed to manually enter the period in the original Excel document.\n",
    "\n",
    "The *dates* column was dropped after extracting both the month and year, now in the form of tuples, into their own respective series. Instead of spelling out the month, I used the replace function to convert each into a two-digit string. Then the string was reassembled into a standard SQL date format (YYYY-MM-DD). Because the temporal resolution is only monthly, I arbitrarily chose the first day of the month.\n",
    "The new list is inserted into *data_T* as a new column in the left most position titled *Date*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data was missing as indicated by (NA) for \"Not Available\" and (S) for \"Sampling Error.\" The replace function was called again, placing the value 0 instead.  \n",
    "\n",
    "<img style=\"float: left;\" src=\"script-concat.png\"/>\n",
    "\n",
    "</br>\n",
    "With the data reshaped and cleaned, it is concatenated with the *prep_data* dataframe before the loop recycles and loads another year's spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with each sheet iterated trough forming a single dataframe, the index needs resetting because each row carried with it the indices from *data_T* dataframe.\n",
    "\n",
    "<img style=\"float: left;\" src=\"script-resetind.png\"/>\n",
    "\n",
    "To ensure all that work is preserved, *to_csv()* is invoked, saving a csv file to the present directory. \n",
    "\n",
    "#### The full ETL script can be found [here](Project8.1-ETL-Machado.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 2.5 Writing an Installation Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the database\n",
    "\n",
    "Now that the data is nice and neat, it is time to load into the MySQL server. To do this, I first need to build a database with table. I could make use of MySQL Workbench, but I will need to define 60 columns for my table. It is much easier to write a script and automate the entire process using the mysql-connector driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-sqlconnect.png\"/>\n",
    "\n",
    "First, I should define how I will connect to the server. My server and login credentials are stored in a .yaml configuration file located in my parent directory. With the assistance of the yaml library I am able to import the file and define the configuration.\n",
    "\n",
    "The driver establishes a connection using the connect function, passing the configuration. By default, any query that alters data will not take effect unless an explicit *commit()* statement is called. This behavior is changed through by enabling the autocommit feature.  \n",
    "\n",
    "A cursor object is also defined. It will be used to make SQL statements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the database, several things need to be decided first. Since there is only one dataframe with unique values, a single table will suffice. The table's column headers will correspond to the dataframes. Since the date should be unique for each row, it could be used as the primary key. However, I decided to add an additional column, *id*, to act as the primary key. To assist with the task *cols* is defined, extracting the dataframe's column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-createtable.png\"/>\n",
    "A query statement is assembled in three sections to build the database infrastructure. The first part consists of three separate commands separated by semicolons and the beginning of a fourth command. \n",
    "\n",
    "In the event the server already contains a database named *mrts*, we first delete it by dropping it. If it doesn't exist, the added statement *IF EXISTS* is there to ensure an error doesn't interrupt execution. After creation, it is selected through the *USE* statement. Any new commands will be directed at the intended database.\n",
    "\n",
    "<br>The fourth command begins at *CREATE TABLE*, with *id* and *Date* explicitly defined as the first two columns. The MRTS data contains integers representing U.S. dollar amounts in millions. *Date* is the only exception, and the reason it is treated separately as a *DATETIME* object.\n",
    "\n",
    "The second section of the query statement begins with a *for* loop. It iterates through the column names skipping *Date*, and appending each to the statement as integer types. \n",
    "\n",
    "Following the loop, the query is closed out, defining which column serves as the primary key, the database engine, and the character set used. The commands are sent to the server via the cursor's execute function with the *multi* option enabled since the statement contains four separate commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-sqldisconnect.png\"/>\n",
    "\n",
    "As a good practice, close the cursor and connection to the SQL server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate the database\n",
    "\n",
    "With a database and table built, it can be populated with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-sqlconnect2.png\"/>  \n",
    "\n",
    "Establish the connection and cursor as before. Don't forget to enable autocommit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 348 rows and 59 columns. Automated entry into the database requires a loop to iterate through each row of the dataframe, construct an *INSERT* query, then execute. As this is performed, *i* is denoted as the row's index, and *r* the values as a series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-sqlquery2.png\"/>\n",
    "Because the field *id* is designed to auto increment, it doesn't need inclusion. However, omitting it creates a mismatch between the number of table columns and number of data points. This scenario requires each value to be mapped to the intended column, thus resolving any ambiguity. But because there are 59 values in each row, it's much cleaner to just include it by referencing the rows index *i*. \n",
    "\n",
    "<br>Since the index begins at *0*, it is incremented by *1* before joining the row as a list *rv*. The *INSERT* query is constructed as a string containing sixty string variables denoted by *%s*. The cursor executes the statement by passing both the string and list of values corresponding to each of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"script-sqldisconnect.png\"/> \n",
    "\n",
    "Again, close the cursor and disconnect. The table is populated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The full ETL script can be found [here](Project8.1-ETL-Machado.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Back to top](#Index)\n",
    "\n",
    "## 3. Analysis and Visualization\n",
    "\n",
    "#### The entire script used for the analysis can be found [here](Project8.2-TS-Analysis-Machado.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 3.1 Running Queries in MySQL Workbech\n",
    "\n",
    "With the dataset now loaded onto the server, queries can be run to access it. Tools available in Python are ideal for data manipulation and plotting. But before jumping into a scrip, I ran several queries on MySQL Workbench first. In doing so, I verified data was uploaded correctly, and ensured my statements would work as intended before inserting them into a script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"sql_query.png\"> \n",
    "<br>Verifying the data loaded corectly involved running a *sum* query for a business type at the begining and end of the list, and only for years 1992 and 2020  in this case, \"Motor vehicle and parts dealers\" and \"Limited service eating places.:\n",
    "\n",
    "<br>```SELECT sum(`Motor vehicle and parts dealers`) \n",
    "AS 'Total'\n",
    "FROM mrts_data\n",
    "WHERE year(`Date`) = 1992```\n",
    "\n",
    "<br>In each case, the number returned matched the value on the original Excel file, providing confidence the data was loaded correctly.\n",
    "\n",
    "I performed additional queries on MySQL Workbench during the analysis, but before placing into my script. The image to the right is an example used to find the total money spent on electronic purchases grouped by month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 3.2 Running Queries From Python\n",
    "\n",
    "To keep the script relatively tidy, I defined a few functions. One of which performs all the required actions to execute a query statement, and return a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"func_sql_query.png\"> \n",
    "\n",
    "The user provides the statement as a string and the configuration file. The auto_commit feature is defaulted to off, but provides the option to enable it. The process to connect and disconnect is the same as described above, but a loop is now required to extract each line of data from the cursor's *fetchall* function.  \n",
    "\n",
    "The following queries were made from the IDE during and used for the analysis:\n",
    "\n",
    "```\n",
    "query = \"\"\"\n",
    "SELECT `id`, `Date`, `Furniture stores` FROM mrts_data\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "SELECT `id`, `Date`, `Electronic shopping and mail-order houses` FROM mrts_data\n",
    "\"\"\"\n",
    "```\n",
    "<br><br>\n",
    "```\n",
    "query = \"\"\"\n",
    "SELECT month(`Date`) AS 'Month', \n",
    "sum(`Electronic shopping and mail-order houses`) AS 'Monthly Totals' \n",
    "FROM mrts_data \n",
    "GROUP BY month(`Date`);\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "SELECT `id`, `Date`, `Book stores` FROM mrts_data\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Each of these statements were then called via the *sql_query* function\n",
    "\n",
    "```\n",
    "eShoping = sql_query(query, '../mrts.yaml') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 3.3 Explore Trends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend analysis is helpful to understand the environment and make predictions about the future. Given the MRTS dataset, we can derive macroeconomic details through the time series. \n",
    "\n",
    "Although before making any charts, it is important to understand inflations role on spending power over time. A dollar's value is generally worth less as time progresses, and is a characteristic of a healthy economy. Regulators try to keep inflation in check with an annual rate of around 2%. With that in mind, if the pattern of spending behavior didn't change over years, we still expect to see an upward trend in spending due to inflation. \n",
    "\n",
    "Take for example the image below, showing the money spent at furniture stores over time. The left plots raw unaltered data, while the right adjusts the values to today's dollar value. The differences are most prominent at the beginning and end. Each show upward trends, meaning Americans are spending more on furniture over time. But the rate of change is significantly lower when adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"730\" src=\"furniture.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other takeaways from the above figure. Downward trends are observed just after the years 2000 and 2007. Those time periods coincide with the dot-com bust and great recession. When compared to other business categories, such as book stores (below), furniture are particularly sensitive to economic downturns. When adjusted for inflation, those downward trends are amplified.\n",
    "\n",
    "Following the great recession, Americans spending in furniture stores slowly picked up. However, spending levels haven't yet reached their pre-recession peak. A detail not captured in the unadjusted graphic.  \n",
    "\n",
    "The sharp downward spike around 2020, is a grim reminder of the Corona virus lockdown, where many businesses were forced to close.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"func_inflate.png\"> \n",
    "<img align=\"left\" src=\"func_make_plot.png\"> \n",
    "\n",
    "Correcting for inflation is accomplished with the displayed function inflate. It accepts a dataframe needing adjustment and another with inflation figures. \n",
    "\n",
    "The [World Bank](https://data.worldbank.org/indicator/FP.CPI.TOTL.ZG?locations=US) tracks inflation numbers for nearly every country on their website. The U.S. data from 1992 - present, is transferred into a new [spreadsheet](usinflation.xls) for ease of reading. \n",
    "\n",
    "A for loop multiplies each value by itself plus the inflation rate, for each year to the present. \n",
    "\n",
    "For ease of plotting the make_plot function is defined to the left. I found the need to rotate the x axis labels for a few plots, so I and included it, color, and save file as options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"eshoppingtrend.png\"> \n",
    "\n",
    "*Electronic shopping and mail-order houses* is a business category from the MRTS set that stood out since it captures all purchases made over the internet. Because records begin in 1992, it is fascinating to see trend evolve as the internet made its debut. \n",
    "\n",
    "What stands out is a logarithmic trend accelerating with each successive year. The impact of the two previous recessions is barely noticeable. The 2020 lockdown also had no observable affect dampening spending as expected. Some argue that online shopping received a boost from the corona virus. While there is a sharp increase in spending during 2020, the rise doesn't deviate from the logarithmic pattern. Future data is needed to draw any conclusions. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"eshoppingmonthly.png\"> \n",
    "\n",
    "Another obvious feature, is the presence of spikes appearing each year. I suspect these anomalies occur during the Christmas holiday season, when holiday shoppers begin feeling generous. \n",
    "\n",
    "<br>To confirm this hypothesis, I summed total spending from 1992 to 2020 and grouped by month. The results are presented in the bar graph to the right. It looks as though November and December spending habits are nearly \\$300 million above normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 3.4 Explore Percentage Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"eshoppingpercent.png\"> \n",
    "\n",
    "Expanding on the trends in internet shopping I was curious to understand just how much of the economy depends on it. \n",
    "\n",
    "The plot to the right represents internet spending as a proportion to the whole. In other words, it is a percentage of the total spending across all categories. The plot looks very similar to the one above, but there are some key differences. \n",
    "\n",
    "The trend change for the recession beginning in 2000 is more pronounced, while the 2008 recession is unobservable. As a percentage of spending, a decrease represents a disproportionate pullback when compared to all other business categories.\n",
    "\n",
    "As expected the overall trend is upward, meaning each year people will spend more on the internet than will in other places. Although, I was disappointed in the numbers and expected to see more. Presently, only 5% to 6% of sales occur online. That leaves a lot of room for growth. \n",
    "\n",
    "In 2020, there is a noticeable spike not seen in the previous graphic. It is unclear how much of the spike is due to increased spending from those trapped in their homes, or a result of not being able to spend in every other category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "### 3.5 Explore Rolling Time Windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"bookstrend1.png\">\n",
    "<img align=\"right\" src=\"bookstrendrolling.png\"> \n",
    "\n",
    "<br><br>The rolling time window is a method to smooth data with large variation. Take for instance bookstore sales from the MRTS dataset. The overall trend is obvious, book store sales are declining and on there way out. However, in a shorter time span it is difficult to discern what is happening. There appear to be wide fluctuations in amplitude that don't correlate to the holiday spending pattern.    \n",
    "\n",
    "<br>To smooth the data, I took the average of a three month period and recorded it as the value for the center month. Then increment by one month and repeat. For example, values for (JAN, FEB, MAR) were (1, 1, 4) respectively. The average is 2, and that value is recorded for FEB. Then do the same for (FEB, MAR, APR) repeating through the entire data set. \n",
    "\n",
    "<br>The result of this method is presented to the right. Notice how the peaks and troughs are dampened, yet the overall trend is preserved. With the introduction of e-readers, smartphones, and tablets, around 2010, it is no surprise to see sales slowly decline year after year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"bookszoom1.png\">\n",
    "<img align=\"right\" src=\"bookszoom2.png\"> \n",
    "\n",
    "<br>Zooming into the reshaped time series, shows other interesting features. The graph to the right shows a period of 24 months spanning 2018 and 2019. That time was selected to represent the most current book store spending habits, without the effects induced by corona virus response efforts. \n",
    "\n",
    "<br>Just below, is a similar plot show a period spanning 2006 and 2007. The time frame is just prior to the great recession and marks the point where sales begin to fall.\n",
    "\n",
    "<br>In both plots, a pattern emerges. Two peaks are seen in each year, one in late summer to early autumn, the other in winter coinciding with the holiday shopping season. This first sudden increase in spending could be the result schools reopening after summer break. Or, it could be attributed to increased summer travel, where reading material helps pass the time on a long trip.\n",
    "\n",
    "<br>The bottom plot, shows spending habits twelve years earlier, and is also telling. The winter peak is substantially higher, \\$200 million higher. That trend is observed in nearly every year when examining the adjusted time series. However, in recent years the difference has significantly decrease to the point where both peaks are approximately equal. Not only are sales declining in general, it appears as though people are also spending less on books for gifts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The entire script used for the analysis can be found [here](Project8.2-TS-Analysis-Machado.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The MRTS dataset contains a trove of information to be used for market analysis. Through the ETL process I was able to reshape, clean and load the data to an SQL server. Then using python, pull targeted columns for analysis. \n",
    "\n",
    "Plotting time series, I showed how vulnerable furniture stores are to recessions, and how ecommerce isn't. The charts also revealed how e-shopping is gaining popularity and bookstores are losing it.\n",
    "\n",
    "There are numerous more analyses that could be performed the data, and the ones covered here are  only a small sample of the possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Back to top](#Index)\n",
    "## References\n",
    "\n",
    "\n",
    "\"E-Commerce In Our Daily Life.\" Dash Technologies. Domains By Proxy, 2021. https://dashtechinc.com/e-commerce-in-our-daily-life/\n",
    "\n",
    "\"Inflation, Consumer Prices (annual%) Data.\" World Bank Data. World Bank Group, 2022. https://data.worldbank.org/indicator/FP.CPI.TOTL.ZG\n",
    "\n",
    "McKinney, Wess and Kluyver, Thomas. â€œpandas: Powerful Python Data Analysis Toolkit - Version 1.4.3.\" The Pandas Development Team, 2022. https://pandas.pydata.org/docs/pandas.pdf\n",
    "\n",
    "\"Monthly Retail Trade.\" United States Census Bureau. U.S. Department of Commerce, 2022. https://www.census.gov/retail/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
